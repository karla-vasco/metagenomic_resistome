#!/bin/bash --login
 
########## Define Resources Needed with SBATCH Lines ##########
#SBATCH --job-name=diamond    # give your job a name for easier identification (same as -J)
#SBATCH --time=24:00:00        # limit of wall clock time - how long will the job take to run? (same as -t)
#SBATCH --ntasks=2           # number of tasks - how many tasks (nodes) does your job require? (same as -n)
#SBATCH --cpus-per-task=12    # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem=200G             # memory required per node - amount of memory (in bytes)
#SBATCH --output=/mnt/scratch/vascokar/mastitis_study/eofiles/card_diamond.%j.out #Standard output
#SBATCH --error=/mnt/scratch/vascokar/mastitis_study/eofiles/card_diamond.%j.err #Standard error log

########## Diplay the job context ######
echo Job: $SLUM_JOB_NAME with ID $SLURM_JOB_ID
echo Running on host `hostname`
echo Job started at `date '+%T %a %d %b %Y'`
echo Directory is `pwd`
echo Using $SLURM_NTASKS processors across $SLURM_NNODES nodes

######### Assign path variables ########

INPUT_DIRECTORY=/mnt/scratch/vascokar/mastitis_study/results/hmd-arg/ORFs
OUTPUT_DIRECTORY=/mnt/scratch/vascokar/mastitis_study/results/CARD/mapped_unique
DATABASE_PATH=/mnt/scratch/vascokar/mastitis_study/data/card/protein/card-homolog.dmnd

########## Modules to Load ##########
module purge
module load DIAMOND/2.0.1

########## Code to Run ###########

cd $INPUT_DIRECTORY

for f in *_contigs_proteins.faa # for each sample f
do
  n=${f%%_contigs_proteins.faa} # strip part of file name

diamond blastp \
-d $DATABASE_PATH \
-q $INPUT_DIRECTORY/${n}_contigs_proteins.faa \
-o $OUTPUT_DIRECTORY/${n}_homolog_matches.sam \
--max-hsps 1 \
-k 1 \
--id 50 \
--outfmt 101

done

##### Final time stamp ######
echo Job finished at `date '+%T %a %d %b %Y'`
